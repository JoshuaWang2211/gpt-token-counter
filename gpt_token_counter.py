import tiktoken, os

SUPPORTED_MODELS = [
    "gpt-4o", "gpt-4o-mini",
    "gpt-4", "gpt-4-turbo",
    "gpt-3.5-turbo",
    "text-davinci-003", "text-davinci-002",
    "text-embedding-ada-002",
    "davinci", "curie", "babbage", "ada",
    "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano",
]

DISALLOW_EXTS = {".docx", ".xlsx", ".pdf"}

def count_tokens(text, model):
    try:
        enc = tiktoken.encoding_for_model(model)
    except KeyError:
        enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))

def get_multiline_input(prompt="è«‹è²¼ä¸Šå¤šè¡Œå…§å®¹ï¼Œè¼¸å…¥ x å¾ŒæŒ‰ Enter çµæŸï¼š"):
    print(prompt)
    lines = []
    while True:
        line = input()
        if line.strip() == "x":
            break
        lines.append(line)
    return "\n".join(lines)

VERSION = "v1.0.0 (2025-06-19)"

def interactive():
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"ğŸ§® GPT Token è¨ˆç®—å™¨ - {VERSION}\n")
    print("ğŸ“Œ æ³¨æ„ï¼šæ”¯æ´æ¨¡å‹æ¸…å–®ä¾ 2025 å¹´ 6 æœˆç‚ºæº–ï¼Œæœªä¾†æ¨¡å‹æ›´æ–°è«‹ç•™æ„æ–°ç‰ˆ\n")
    print("ğŸ“Œ ä½¿ç”¨èªªæ˜\n")
    print("1ï¸âƒ£ è¼¸å…¥æ–¹å¼ï¼š")
    print("   - å–®è¡Œæ–‡å­—ï¼šç›´æ¥è¼¸å…¥æ–‡å­—å¾ŒæŒ‰ Enter")
    print("   - å¤šè¡Œæ–‡å­—ï¼šç”¨æ–¼è²¼ä¸Šå¤šè¡Œæˆ–å¤šæ®µæ–‡ç« ï¼Œè¼¸å…¥ /multiï¼ŒçµæŸè«‹è¼¸å…¥ x å¾ŒæŒ‰ Enter")
    print("   - æª”æ¡ˆå…§å®¹ï¼šè¼¸å…¥æª”æ¡ˆå®Œæ•´è·¯å¾‘ï¼Œä¾‹å¦‚ ./file.txtã€‚å¦‚æª”æ¡ˆåœ¨åŒä¸€å€‹è³‡æ–™å¤¾ä¸­ï¼Œå¯ç›´æ¥è¼¸å…¥æª”æ¡ˆå")
    print("  âš ï¸ åƒ…æ”¯æ´ç´”æ–‡å­—æª”æ¡ˆï¼Œä¸æ”¯æ´ .docxã€.xlsxã€.pdf ç­‰æª”æ¡ˆ\n")
    print("2ï¸âƒ£ å¯ç”¨æŒ‡ä»¤ï¼š")
    print("   - /model [æ¨¡å‹åç¨±]    åˆ‡æ›æ¨¡å‹ (ä¾‹å¦‚ï¼š/model gpt-4.1)")
    print("   - /list                åˆ—å‡ºæ”¯æ´æ¨¡å‹")
    print("   - /multi               å¤šè¡Œè¼¸å…¥\n")
    print("3ï¸âƒ£ çµæŸæœ¬ç¨‹å¼è«‹ç›´æ¥æŒ‰ Enter\n")

    model = "gpt-4o"
    print(f"ğŸ‘‰ ç•¶å‰æ¨¡å‹ï¼š{model}\n")

    while True:
        inp = input("è¼¸å…¥æ–‡å­— / æª”æ¡ˆ / å‘½ä»¤ï¼š").strip()
        if not inp:
            break

        # æŒ‡ä»¤ï¼šåˆ—å‡ºæ¨¡å‹
        if inp.lower() == "/list":
            print("ğŸ“‹ æ”¯æ´æ¨¡å‹å¦‚ä¸‹ï¼š")
            print(", ".join(SUPPORTED_MODELS), "\n")
            continue

        # æŒ‡ä»¤ï¼šåˆ‡æ›æ¨¡å‹
        if inp.lower().startswith("/model"):
            parts = inp.split()
            if len(parts) == 2:
                cmd = parts[1]
                if cmd in SUPPORTED_MODELS:
                    model = cmd
                    print(f"âœ… æ¨¡å‹å·²åˆ‡æ›ç‚ºï¼š{model}\n")
                else:
                    print(f"âŒ ä¸æ”¯æ´ï¼š{cmd}")
                    print("ğŸ“Œ å¯ç”¨æ¨¡å‹è«‹ç”¨ /list æŸ¥çœ‹\n")
            else:
                print("âš ï¸ è«‹è¼¸å…¥ `/model æ¨¡å‹åç¨±`\n")
            continue

        # å¤šè¡Œè¼¸å…¥æ¨¡å¼
        elif inp.lower() == "/multi":
            text = get_multiline_input()
            src = "[å¤šè¡Œè¼¸å…¥]"

        # æª”æ¡ˆåˆ¤æ–·
        elif os.path.exists(inp):
            ext = os.path.splitext(inp)[1].lower()
            if ext in DISALLOW_EXTS:
                print("âŒ ä¸æ”¯æ´è©²æª”æ¡ˆé¡å‹ï¼ˆç´”æ–‡å­—ä»¥å¤–è«‹å…ˆè½‰æª”ï¼‰\n")
                continue
            try:
                with open(inp, encoding='utf-8') as f:
                    text = f.read()
                src = f"[æª”æ¡ˆ]{inp}"
            except Exception as e:
                print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•—ï¼š{e}\n")
                continue

        # æ–‡å­—åˆ¤æ–·
        else:
            if "\n" in inp or "\\n" in inp:
                if "\\n" in inp:
                    text = inp.replace("\\n", "\n")
                else:
                    text = inp
                src = "[å¤šè¡Œæ–‡å­—]"
            else:
                text = inp
                src = "[å–®è¡Œæ–‡å­—]"

        cnt = count_tokens(text, model)
        print(f"âœ… ä¾†æºï¼š{src} | æ¨¡å‹ï¼š{model} | Token æ•¸ï¼š{cnt}\n")

    input("ğŸ‘‹ æŒ‰ Enter é—œé–‰")

if __name__ == "__main__":
    interactive()
